{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb912d5",
   "metadata": {},
   "source": [
    "conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch\n",
    "\n",
    "install resnest using github url: pip install git+https://github.com/zhanghang1989/ResNeSt\n",
    "\n",
    "or using pypi: pip install resnest --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0a8ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "from PIL import Image, ImageOps\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from resnest.torch import resnest50\n",
    "\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torchvision.transforms import Lambda\n",
    "import argparse\n",
    "import copy\n",
    "import random\n",
    "import numbers\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d5455b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available()==True:\n",
    "    device=\"cuda:2\"\n",
    "else:\n",
    "    device =\"cpu\"\n",
    "    \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55c9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e37885b",
   "metadata": {},
   "source": [
    "# 1. Models: M1, M2, M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbf6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1  RCNet \n",
    "class M1_resnet_lstm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M1_resnet_lstm, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.share = torch.nn.Sequential()    # self.cnn = self.share\n",
    "        self.share.add_module(\"conv1\", resnet.conv1)\n",
    "        self.share.add_module(\"bn1\", resnet.bn1)\n",
    "        self.share.add_module(\"relu\", resnet.relu)\n",
    "        self.share.add_module(\"maxpool\", resnet.maxpool)\n",
    "        self.share.add_module(\"layer1\", resnet.layer1)\n",
    "        self.share.add_module(\"layer2\", resnet.layer2)\n",
    "        self.share.add_module(\"layer3\", resnet.layer3)\n",
    "        self.share.add_module(\"layer4\", resnet.layer4)\n",
    "        self.share.add_module(\"avgpool\", resnet.avgpool)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.lstm = nn.LSTM(2048, 512, batch_first=True) # feature : 512\n",
    "        self.fc = nn.Linear(512, 19)      # 512 feature -> 19 classes\n",
    "\n",
    "\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][0])\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][1])\n",
    "        init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 216,216)  # 384 216 x.view(-1, 3, 224, 224) \n",
    "        x = self.share.forward(x)   # output [batchsize, 2048,1,1]\n",
    "        x = x.view(-1, sequence_length, 2048) \n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        y, _ = self.lstm(x)  # 512\n",
    "        y = y.contiguous().view(-1, 512) # feature \n",
    "        y = self.dropout(y)\n",
    "        y = self.fc(y)  # predict\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bf3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b34135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2: densenet + lstm\n",
    "class M2_densenet_lstm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M2_densenet_lstm, self).__init__()\n",
    "        resnet = models.densenet169(pretrained=True) #pretrained=True\n",
    "        self.share = torch.nn.Sequential()\n",
    "        self.share.add_module(\"features\", resnet.features)\n",
    "        #self.share.add_module(\"avgpool\", resnet.avgpool)\n",
    "        self.avg = nn.AvgPool2d(6)\n",
    "\n",
    "        # self.share.add_module(\"classifier\", resnet.classifier)\n",
    "        #self.fc_1 = nn.Linear(9216, 4096)\n",
    "        \n",
    "        # \n",
    "        self.lstm = nn.LSTM(1664, 512, batch_first=True)\n",
    "#        self.lstm = nn.LSTM(2028, 512, batch_first=True)\n",
    "        self.fc = nn.Linear(512, 19)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][0])\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][1])\n",
    "        init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 216, 216)\n",
    "        x = self.share.forward(x) # ([100, 1664, 6, 6])   # ([100,2048,1,1])\n",
    "        x = self.avg(x)\n",
    "        x = x.view(-1, sequence_length, 1664)  \n",
    "        self.lstm.flatten_parameters()\n",
    "        y, _ = self.lstm(x)\n",
    "        y = y.contiguous().view(-1, 512)\n",
    "        y = self.dropout(y)\n",
    "        y = self.fc(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93220f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3  ResNeSt + lstm\n",
    "class M3_resnest_lstm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M3_resnest_lstm, self).__init__()\n",
    "        resnet = resnest50(pretrained=True)\n",
    "        self.share = torch.nn.Sequential()    # self.cnn = self.share\n",
    "        self.share.add_module(\"conv1\", resnet.conv1)\n",
    "        self.share.add_module(\"bn1\", resnet.bn1)\n",
    "        self.share.add_module(\"relu\", resnet.relu)\n",
    "        self.share.add_module(\"maxpool\", resnet.maxpool)\n",
    "        self.share.add_module(\"layer1\", resnet.layer1)\n",
    "        self.share.add_module(\"layer2\", resnet.layer2)\n",
    "        self.share.add_module(\"layer3\", resnet.layer3)\n",
    "        self.share.add_module(\"layer4\", resnet.layer4)\n",
    "        self.share.add_module(\"avgpool\", resnet.avgpool)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.lstm = nn.LSTM(2048, 512, batch_first=True) # feature : 512\n",
    "        self.fc = nn.Linear(512, 19)      # 512 feature -> 19 classes\n",
    "\n",
    "\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][0])\n",
    "        init.xavier_normal_(self.lstm.all_weights[0][1])\n",
    "        init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 216,216)  # 384 216 x.view(-1, 3, 224, 224) \n",
    "        x = self.share.forward(x)   # output [batchsize, 2048,1,1]\n",
    "        x = x.view(-1, sequence_length, 2048) \n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        y, _ = self.lstm(x)  # 512\n",
    "        y = y.contiguous().view(-1, 512) # feature \n",
    "        y = self.dropout(y)\n",
    "        y = self.fc(y)  # predict\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577744b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = M1_resnet_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1191acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = M2_densenet_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43344533",
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = M3_resnest_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c6531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e630bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae31985",
   "metadata": {},
   "source": [
    "# 2. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f09ad392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCrossEntropy(torch.nn.Module):\n",
    "    '''\n",
    "    WCE\n",
    "    '''       \n",
    "     # 6-25\n",
    "    def __init__(self, weight=torch.Tensor([0.0033, 0.4182, 0.1321, 0.0234, 0.0344, 0.0146, 0.0428, 0.0140, 0.0092,\n",
    "        0.0272, 0.0096, 0.0323, 0.0341, 0.0508, 0.0151, 0.0160, 0.0365, 0.0738,\n",
    "        0.0128])):\n",
    "        super(WeightedCrossEntropy, self).__init__()\n",
    "        \n",
    "        weight = weight.to(device)\n",
    "        self.weighted_cross_entropy = nn.CrossEntropyLoss(weight=weight)\n",
    "        \n",
    "    def forward(self, inputs, target):\n",
    "        return self.weighted_cross_entropy.forward(inputs, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e23cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a91869a0",
   "metadata": {},
   "source": [
    "# 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45f1b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "class CataractsDataset(Dataset):\n",
    "    def __init__(self, file_paths,file_labels, transform=None,loader=pil_loader):\n",
    "        self.file_paths = file_paths\n",
    "        self.file_labels_phase = file_labels[:,0]\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_names = self.file_paths[index]\n",
    "        labels = self.file_labels_phase[index]\n",
    "        imgs = self.loader(img_names)\n",
    "        if self.transform is not None:\n",
    "            imgs = self.transform(imgs)\n",
    "\n",
    "        return imgs, labels, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e80c9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(data_path):\n",
    "    with open(data_path, 'rb') as f:\n",
    "        train_test_paths_labels = pickle.load(f)\n",
    "    train_paths_50 = train_test_paths_labels[0]\n",
    "    val_paths_50 = train_test_paths_labels[1]\n",
    "    train_labels_50 = train_test_paths_labels[2]\n",
    "    val_labels_50 = train_test_paths_labels[3]\n",
    "    train_num_each_50 = train_test_paths_labels[4]\n",
    "    val_num_each_50 = train_test_paths_labels[5]\n",
    "\n",
    "    print('train_paths_20  : {:6d}'.format(len(train_paths_50)))\n",
    "    print('train_labels_20 : {:6d}'.format(len(train_labels_50)))\n",
    "    print('valid_paths_5  : {:6d}'.format(len(val_paths_50)))\n",
    "    print('valid_labels_5 : {:6d}'.format(len(val_labels_50)))\n",
    "\n",
    "    # train_labels_19 = np.asarray(train_labels_19, dtype=np.int64) yilin comment\n",
    "    train_labels_50 = np.asarray(train_labels_50, dtype=np.int64)\n",
    "    val_labels_50 = np.asarray(val_labels_50, dtype=np.int64)\n",
    "    \n",
    "    train_transforms = transforms.Compose([\n",
    "            transforms.CenterCrop(216),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(5),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    test_transforms = transforms.Compose([\n",
    "            transforms.CenterCrop(216),\n",
    "            transforms.ToTensor(),\n",
    "\n",
    "        ])\n",
    "\n",
    "    train_dataset_50 = CataractsDataset(train_paths_50, train_labels_50, train_transforms)\n",
    "    val_dataset_50 = CataractsDataset(val_paths_50, val_labels_50, test_transforms)\n",
    "\n",
    "    return train_dataset_50, train_num_each_50,val_dataset_50, val_num_each_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "affc83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_paths_20  :  14160\n",
      "train_labels_20 :  14160\n",
      "valid_paths_5  :   2323\n",
      "valid_labels_5 :   2323\n"
     ]
    }
   ],
   "source": [
    "train_dataset_50, train_num_each_50, \\\n",
    "val_dataset_50, val_num_each_50 = get_dataset('../../gen_datasets/train_val_paths_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c732d96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CataractsDataset at 0x7f9230252c40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1d7d8a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[461,\n",
       " 625,\n",
       " 915,\n",
       " 532,\n",
       " 852,\n",
       " 475,\n",
       " 719,\n",
       " 467,\n",
       " 684,\n",
       " 458,\n",
       " 607,\n",
       " 414,\n",
       " 465,\n",
       " 2368,\n",
       " 564,\n",
       " 515,\n",
       " 688,\n",
       " 372,\n",
       " 619,\n",
       " 1360]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the frame number of each video in training set\n",
    "train_num_each_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a8d64d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[479, 394, 583, 442, 425]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the frame number of each video in val set\n",
    "val_num_each_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c15e97",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37156af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceSampler(Sampler):\n",
    "    def __init__(self, data_source, idx):\n",
    "        super().__init__(data_source)\n",
    "        self.data_source = data_source\n",
    "        self.idx = idx\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54de89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sliding window\n",
    "def get_start_idx(sequence_length, list_each_length):\n",
    "    count = 0\n",
    "    idx = []\n",
    "    for i in range(len(list_each_length)):\n",
    "        for j in range(count, count + (list_each_length[i] + 1 - sequence_length)):\n",
    "            idx.append(j)\n",
    "        count += list_each_length[i]\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4926d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dataset, train_num_each, val_dataset, val_num_each):\n",
    "    # TensorBoard\n",
    "    writer = SummaryWriter(tensorboard_path)\n",
    "\n",
    "    # choose start index for sequence \n",
    "    train_useful_start_idx = get_start_idx(sequence_length, train_num_each)\n",
    "    val_useful_start_idx = get_start_idx(sequence_length, val_num_each)\n",
    "\n",
    "    num_train_we_use = len(train_useful_start_idx)\n",
    "    num_val_we_use = len(val_useful_start_idx)\n",
    "\n",
    "    \n",
    "    train_idx = []\n",
    "    for i in range(num_train_we_use):\n",
    "        for j in range(sequence_length):\n",
    "            train_idx.append(train_useful_start_idx[i] + j)\n",
    "\n",
    "    val_idx = []\n",
    "    for i in range(num_val_we_use):\n",
    "        for j in range(sequence_length):\n",
    "            val_idx.append(val_useful_start_idx[i] + j)\n",
    "\n",
    "    num_train_all = len(train_idx)\n",
    "    num_val_all = len(val_idx)\n",
    "\n",
    "    print('num train start idx : {:6d}'.format(len(train_useful_start_idx)))\n",
    "    print('num of all train use: {:6d}'.format(num_train_all))\n",
    "    print('num of all valid use: {:6d}'.format(num_val_all))\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=val_batch_size,\n",
    "        sampler=SeqSampler(val_dataset, val_idx),\n",
    "        num_workers=workers,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    #####################################\n",
    "    #model = resnet_lstm()\n",
    "    # model.load_state_dict(torch.load(pretrained_model_path))\n",
    "    #####################################   \n",
    "        \n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    criterion_phase = WeightedCrossEntropy() #nn.CrossEntropyLoss(size_average=False)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "    \n",
    "    best_val_accuracy_phase = 0.0\n",
    "    correspond_train_acc_phase = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        np.random.shuffle(train_useful_start_idx)\n",
    "        train_idx = []\n",
    "        for i in range(num_train_we_use):\n",
    "            for j in range(sequence_length):\n",
    "                train_idx.append(train_useful_start_idx[i] + j)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=train_batch_size,\n",
    "            sampler=SequenceSampler(train_dataset, train_idx),\n",
    "            num_workers=workers,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "        # in training mode.\n",
    "        model.train()\n",
    "        train_loss_phase = 0.0\n",
    "        train_corrects_phase = 0\n",
    "        batch_progress = 0.0\n",
    "        running_loss_phase = 0.0\n",
    "        minibatch_correct_phase = 0.0\n",
    "        train_start_time = time.time()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, labels_phase = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            labels_phase = labels_phase[(sequence_length - 1)::sequence_length]\n",
    "\n",
    "            inputs = inputs.view(-1, sequence_length, 3, 216,216) #224, 224)\n",
    "            outputs_phase = model.forward(inputs)\n",
    "            outputs_phase = outputs_phase[sequence_length - 1::sequence_length]\n",
    "\n",
    "            _, preds_phase = torch.max(outputs_phase.data, 1)\n",
    "            loss_phase = criterion_phase(outputs_phase, labels_phase)\n",
    "\n",
    "            loss = loss_phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_phase += loss_phase.data.item()\n",
    "            train_loss_phase += loss_phase.data.item()\n",
    "\n",
    "            batch_corrects_phase = torch.sum(preds_phase == labels_phase.data)\n",
    "            train_corrects_phase += batch_corrects_phase\n",
    "\n",
    "\n",
    "            if (i+1)*train_batch_size >= num_train_all:               \n",
    "                running_loss_phase = 0.0\n",
    "                minibatch_correct_phase = 0.0\n",
    "\n",
    "            batch_progress += 1\n",
    "            if batch_progress*train_batch_size >= num_train_all:\n",
    "                percent = 100.0\n",
    "                print('Train progress: %s [%d/%d]' % (str(percent) + '%', num_train_all, num_train_all), end='\\n')\n",
    "            else:\n",
    "                percent = round(batch_progress*train_batch_size / num_train_all * 100, 2)\n",
    "                print('Train progress: %s [%d/%d]' % (str(percent) + '%', batch_progress*train_batch_size, num_train_all), end='\\r')\n",
    "\n",
    "        train_elapsed_time = time.time() - train_start_time\n",
    "        train_accuracy_phase = float(train_corrects_phase) / float(num_train_all) * sequence_length\n",
    "        train_average_loss_phase = train_loss_phase / num_train_all * sequence_length\n",
    "\n",
    "        \n",
    "        writer.add_scalar('train acc epoch phase',\n",
    "                          float(train_accuracy_phase),epoch)\n",
    "        writer.add_scalar('train loss epoch phase',\n",
    "                          float(train_average_loss_phase),epoch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #  in evaluation mode.\n",
    "        model.eval()\n",
    "        val_loss_phase = 0.0\n",
    "        val_corrects_phase = 0\n",
    "        val_start_time = time.time()\n",
    "        val_progress = 0\n",
    "        val_all_preds_phase = []\n",
    "        val_all_labels_phase = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "\n",
    "                inputs, labels_phase = data[0].to(device), data[1].to(device)\n",
    "\n",
    "\n",
    "                labels_phase = labels_phase[(sequence_length - 1)::sequence_length]\n",
    "\n",
    "                inputs = inputs.view(-1, sequence_length, 3, 216,216) # 224 224\n",
    "                outputs_phase = model.forward(inputs)\n",
    "                outputs_phase = outputs_phase[sequence_length - 1::sequence_length]\n",
    "\n",
    "                _, preds_phase = torch.max(outputs_phase.data, 1)\n",
    "                loss_phase = criterion_phase(outputs_phase, labels_phase)\n",
    "\n",
    "                val_loss_phase += loss_phase.data.item()\n",
    "\n",
    "                val_corrects_phase += torch.sum(preds_phase == labels_phase.data)\n",
    "\n",
    "\n",
    "                for i in range(len(preds_phase)):\n",
    "                    val_all_preds_phase.append(int(preds_phase.data.cpu()[i]))\n",
    "                for i in range(len(labels_phase)):\n",
    "                    val_all_labels_phase.append(int(labels_phase.data.cpu()[i]))\n",
    "\n",
    "\n",
    "                val_progress += 1\n",
    "                if val_progress*val_batch_size >= num_val_all:\n",
    "                    percent = 100.0\n",
    "                    print('Val progress: %s [%d/%d]' % (str(percent) + '%', num_val_all, num_val_all), end='\\n')\n",
    "                else:\n",
    "                    percent = round(val_progress*val_batch_size / num_val_all * 100, 2)\n",
    "                    print('Val progress: %s [%d/%d]' % (str(percent) + '%', val_progress*val_batch_size, num_val_all), end='\\r')\n",
    "\n",
    "        val_elapsed_time = time.time() - val_start_time\n",
    "        val_accuracy_phase = float(val_corrects_phase) / float(num_val_we_use)\n",
    "        val_average_loss_phase = val_loss_phase / num_val_we_use\n",
    "\n",
    "\n",
    "        writer.add_scalar('validation acc epoch phase',\n",
    "                          float(val_accuracy_phase),epoch)\n",
    "        writer.add_scalar('validation loss epoch phase',\n",
    "                          float(val_average_loss_phase),epoch)\n",
    "\n",
    "        print('epoch: {:4d}'\n",
    "              ' train in: {:2.0f}m{:2.0f}s'\n",
    "              ' train loss(phase): {:4.4f}'\n",
    "              ' train accu(phase): {:.4f}'\n",
    "              ' valid in: {:2.0f}m{:2.0f}s'\n",
    "              ' valid loss(phase): {:4.4f}'\n",
    "              ' valid accu(phase): {:.4f}'\n",
    "              .format(epoch,\n",
    "                      train_elapsed_time // 60,\n",
    "                      train_elapsed_time % 60,\n",
    "                      train_average_loss_phase,\n",
    "                      train_accuracy_phase,\n",
    "                      val_elapsed_time // 60,\n",
    "                      val_elapsed_time % 60,\n",
    "                      val_average_loss_phase,\n",
    "                      val_accuracy_phase))\n",
    "\n",
    "\n",
    "        # choose the best model by accuracy\n",
    "        if val_accuracy_phase > best_val_accuracy_phase:\n",
    "            best_val_accuracy_phase = val_accuracy_phase\n",
    "            correspond_train_acc_phase = train_accuracy_phase\n",
    "            #copy the best model\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "        if val_accuracy_phase == best_val_accuracy_phase:\n",
    "            if train_accuracy_phase > correspond_train_acc_phase:\n",
    "                correspond_train_acc_phase = train_accuracy_phase\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "\n",
    "        save_val_phase = int(\"{:4.0f}\".format(best_val_accuracy_phase * 10000))\n",
    "        save_train_phase = int(\"{:4.0f}\".format(correspond_train_acc_phase * 10000))\n",
    "        base_name = \"lstm\" \\\n",
    "                     + \"_epoch_\" + str(best_epoch) \\\n",
    "                     + \"_length_\" + str(sequence_length) \\\n",
    "                     + \"_batch_\" + str(train_batch_size) \\\n",
    "                     + \"_train_\" + str(save_train_phase) \\\n",
    "                     + \"_val_\" + str(save_val_phase)\n",
    "        \n",
    "        #model_save_path = 'sl10_flip1_lr5e-5/'\n",
    "        \n",
    "        torch.save(best_model_wts, \"/media/yilin/catarcnet/best_model/\"+model_save_path+base_name+\".pth\")\n",
    "        print(\"best_epoch\",str(best_epoch))\n",
    "        # model.module.state_dict()\n",
    "        \n",
    "        torch.save(model.state_dict(), \"/media/yilin/catarcnet/temp/\"+model_save_path+ \"latest_model_\"+str(epoch)+\".pth\")\n",
    "              \n",
    "\n",
    "    return \"Complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b51b32dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train configuration\n",
    "\n",
    "sequence_length = 10\n",
    "train_batch_size = 100\n",
    "val_batch_size = 100\n",
    "epochs = 1\n",
    "workers = 2\n",
    "learning_rate = 5e-5\n",
    "MODEL = M1_resnet_lstm() # M2_densenet_lstm() /  M3_resnest_lstm()\n",
    "\n",
    "# M1 = M1_resnet_lstm()\n",
    "# M2 = M2_densenet_lstm()\n",
    "# M3 = M3_resnest_lstm()\n",
    "\n",
    "\n",
    "##################################\n",
    "device = \"cuda:1\"  \n",
    "model_save_path = 'resnet/sl10_lr5e-5_6-25train/' # 'resnet/sl10_lr5e-5_6-25train/' cuda:0\n",
    "tensorboard_path = 'runs/' + model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38149267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e62e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_paths_20  :  14160\n",
      "train_labels_20 :  14160\n",
      "valid_paths_5  :   2323\n",
      "valid_labels_5 :   2323\n"
     ]
    }
   ],
   "source": [
    "# get dataset \n",
    "train_dataset_50, train_num_each_50, \\\n",
    "val_dataset_50, val_num_each_50 = get_data('../../gen_datasets/train_val_paths_labels.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c56ec17f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train start idx :  13980\n",
      "num of all train use: 139800\n",
      "num of all valid use:  22780\n",
      "Train progress: 100.0% [139800/139800]\n",
      "Val progress: 100.0% [22780/22780]\n",
      "epoch:    0 train in: 13m35s train loss(phase): 0.0661 train accu(phase): 0.6985 valid in:  0m40s valid loss(phase): 0.0883 valid accu(phase): 0.6475\n",
      "best_epoch 0\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10    # the length of input clip \n",
    "train_batch_size = 100  # batch size \n",
    "val_batch_size = 100     \n",
    "epochs = 1 \n",
    "workers = 2   \n",
    "learning_rate = 5e-5\n",
    "MODEL = M1_resnet_lstm() # M2_densenet_lstm() /  M3_resnest_lstm()\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "device = \"cuda:1\"  \n",
    "model_save_path = 'resnet/sl10_lr5e-5_6-25train/' # 'resnet/sl10_lr5e-5_6-25train/' cuda:0\n",
    "tensorboard_path = 'runs/' + model_save_path\n",
    "###########################################\n",
    "\n",
    "\n",
    "# train M1\n",
    "train_model(MODEL,(train_dataset_50),(train_num_each_50),(val_dataset_50),(val_num_each_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea1e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae892b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c07ecfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train start idx :  13980\n",
      "num of all train use: 139800\n",
      "num of all valid use:  22780\n",
      "Train progress: 100.0% [139800/139800]\n",
      "Val progress: 100.0% [22780/22780]\n",
      "epoch:    0 train in: 10m33s train loss(phase): 0.0642 train accu(phase): 0.7127 valid in:  0m30s valid loss(phase): 0.0765 valid accu(phase): 0.6932\n",
      "best_epoch 0\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10    # the length of input clip \n",
    "train_batch_size = 100  # batch size \n",
    "val_batch_size = 100     \n",
    "epochs = 1 \n",
    "workers = 2   \n",
    "learning_rate = 5e-5\n",
    "MODEL = M2_densenet_lstm() # M2_densenet_lstm() /  M3_resnest_lstm()\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "device = \"cuda:2\"  \n",
    "model_save_path = 'densenet/sl10_lr5e-5_6-25train/' # 'resnet/sl10_lr5e-5_6-25train/' cuda:0\n",
    "tensorboard_path = 'runs/' + model_save_path\n",
    "###########################################\n",
    "\n",
    "\n",
    "# train M2\n",
    "train_model(MODEL,(train_dataset_50),(train_num_each_50),(val_dataset_50),(val_num_each_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b2d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8643306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train start idx :  13980\n",
      "num of all train use: 139800\n",
      "num of all valid use:  22780\n",
      "Train progress: 100.0% [139800/139800]\n",
      "Val progress: 100.0% [22780/22780]\n",
      "epoch:    0 train in: 10m23s train loss(phase): 0.0627 train accu(phase): 0.7154 valid in:  0m33s valid loss(phase): 0.0849 valid accu(phase): 0.6637\n",
      "best_epoch 0\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10    # the length of input clip \n",
    "train_batch_size = 100  # batch size \n",
    "val_batch_size = 100     \n",
    "epochs = 1 \n",
    "workers = 2   \n",
    "learning_rate = 5e-5\n",
    "MODEL = M3_resnest_lstm() # M2_densenet_lstm() /  M3_resnest_lstm()\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "device = \"cuda:2\"  \n",
    "model_save_path = 'resnest/sl10_lr1e-5_6-25train/' # 'resnet/sl10_lr5e-5_6-25train/' cuda:0\n",
    "tensorboard_path = 'runs/' + model_save_path\n",
    "###########################################\n",
    "\n",
    "\n",
    "# train M3_resnest_lstm()\n",
    "train_model(MODEL,(train_dataset_50),(train_num_each_50),(val_dataset_50),(val_num_each_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbc87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0da6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf0270b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_paths_20  :   1456\n",
      "train_labels_20 :   1456\n",
      "valid_paths_5  :    867\n",
      "valid_labels_5 :    867\n"
     ]
    }
   ],
   "source": [
    "# 3 training videos, 2 val videos\n",
    "train_dataset_5, train_num_each_5, \\\n",
    "val_dataset_5, val_num_each_5 = get_dataset('../../gen_datasets/train_val_paths_labels_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f47de5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train start idx :   1429\n",
      "num of all train use:  14290\n",
      "num of all valid use:   8490\n",
      "Train progress: 100.0% [14290/14290]\n",
      "Val progress: 100.0% [8490/8490]\n",
      "epoch:    0 train in:  1m 1s train loss(phase): 0.1216 train accu(phase): 0.5430 valid in:  0m11s valid loss(phase): 0.0853 valid accu(phase): 0.6737\n",
      "best_epoch 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 10    # the length of input clip \n",
    "train_batch_size = 100  # batch size \n",
    "val_batch_size = 100     \n",
    "epochs = 1 \n",
    "workers = 2   \n",
    "learning_rate = 5e-5\n",
    "MODEL = M1_resnet_lstm() # M2_densenet_lstm() /  M3_resnest_lstm()\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "device = \"cuda:1\"  \n",
    "model_save_path = 'resnet/sl10_lr5e-5_6-25train/' # 'resnet/sl10_lr5e-5_6-25train/' cuda:0\n",
    "tensorboard_path = 'runs/' + model_save_path\n",
    "###########################################\n",
    "\n",
    "\n",
    "# train M1\n",
    "train_model(MODEL,(train_dataset_5),(train_num_each_5),(val_dataset_5),(val_num_each_5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
